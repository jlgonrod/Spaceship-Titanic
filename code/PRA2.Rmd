---
title: "Spaceship-Titanic"
author: "Juan Luis González Rodríguez & Rocío González Martínez"
date: "`r Sys.Date()`"

output:
  pdf_document:
    toc: true
    toc_depth: 4
  html_document: default
toc-title: "Índice"
bibliography: cites.bib
csl: ieee.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE}
# Package names
packages <- c("tidyr", "dplyr","ggplot2", "keras","reshape2","tidyverse",
              "caret","ROCR", "knitr", 'nortest', "bestNormalize")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

set.seed(15463)
```

# 1 Contexto

## 1.1 Descripción del Dataset

El dataset *Spaceship Titanic* @kaggle_2022_spaceship. Este dataset es parte de la competición homónima y tiene por objetivo crear un algoritmo para predecir qué pasajeros han desaparecido al colisionar una nave espacial denominada Titanic con una anomalía espaciotemporal. Con el conjunto de datos, se pretende predecir si el pasajero ha desaparecido o no, para enviar a un equipo a rescatarle. Para ello, se facilitan 2 ficheros (separados por entrenamiento y test), Se usará el fichero *train.csv* en uno para limpiar todos los registros y posteriormente se usará este para entrenar al modelo. Con el fichero test podremos probar el modelo (no incluye la variable objetivo).

Descripción de **Train.csv**: Conjunto de datos con información de unos 8 700 pasajeros. Este consta de los campos que se especifican más abajo.

| Nombre    | Tipo    | Descripción   |
| --------- | ------- | ------------- |
| PassengerId|chr|Identificador de cada pasajero. El formato es gggg_pp (gggg hace referencia al grupo de pasajeros y pp al número dentro del grupo). Normalmente los miembros del grupo son familia.|
| --------- | ------- | ------------- |
|HomePlanet|factor|Platena de origen del pasajero.|
| --------- | ------- | ------------- |
|CryoSleep| logical | Indica si el pasajero está en animación suspendida durante el viaje o no.|
| --------- | ------- | ------------- |
|Cabin|chr|Indican la cabina del pasajero. El formato es "plataforma/numero/lado". Lado será P o S|
| --------- | ------- | ------------- |
|Destination|factor|Indica el nombre del planeta de destino del pasajero.|
| --------- | ------- | ------------- |
|Age|integer|Indica la edad biológica del pasajero en años en el momento del viaje.|
| --------- | ------- | ------------- |
|VIP|logical|Indica si el pasajero ha pagado por un servicio VIP o no|
| --------- | ------- | ------------- |
|RoomService, FoodCouert, ShopingMall, Spa, VRDeck|numeric|Indica la cantidad de dinero que el pasajero ha gastado en cada uno de los servicios|
| --------- | ------- | ------------- |
|Name|chr|Indica el nombre y apellido del pasajero|
| --------- | ------- | ------------- |
|Transported|logical|Variable objetivo, indica si el pasajero ha sido transportado a otra dimensión o no (es decir si ha desaparecido).|

La estructura del dataset es la siguiente:

```{r}
df <- read.csv("~/MASTER CIENCIA DE DATOS/Tipologia y ciclo de vida de los datos/Practicas/Práctica2/Ejercicio/Repositorio/data/raw_data/train.csv",
               colClasses=c("HomePlanet"="factor",
                            "CryoSleep"="logical",
                            "Destination"="factor",
                            "VIP"="logical",
                            "Transported"="logical"))
df$Age <- as.integer(df$Age)

str(df)
```


## 1.2 ¿Por qué es importante y qué pregunta/problema pretende responder?

El objetivo que se persigue con el proyecto es el de, partiendo del conjunto de datos anteriormente comentado, desarrollar un modelo supervisado que permita responder a la pregunta: **¿Ha desaparecido el pasajero que se indica?**

Con ello, la tripulación podrá dirigir los esfuerzos de una manera más eficiente y maximizar las vidas salvadas.

# 2 Integración y selección de los datos de interes.

Solo hay 1 fichero de origen, por lo que no hay que combinar los datos de diferentes fuentes.

Como ya se tiene a los usuarios identificados a los usuarios en base a los identificadores, no es necesario almacenar sus nombres de cara al análisis. Por otro lado, de los campos *Passenger_id* y *Cabin* se pueden extraer aún más campos como el grupo y número dentro del grupo en el primer caso y la plataforma, número de cabina y lado en el segundo.

Se elimina la variable *Name* y se crean las nuevas variables derivadas.

```{r}
df <- select(df, -Name)
```

```{r}
df <- df %>%
  mutate(PassengerGroup=
           as.character(sapply(strsplit(PassengerId,"_"), `[`, 1))) %>%
  mutate(PassengerNumInGroup=
           as.factor(sapply(strsplit(PassengerId,"_"), `[`, 2))) %>%
  mutate(CabinPlatform = 
           as.factor(sapply(strsplit(Cabin,"/"), `[`, 1))) %>%
    mutate(CabinNumber = 
           as.integer(sapply(strsplit(Cabin,"/"), `[`, 2))) %>%
    mutate(CabinSide = 
           as.factor(sapply(strsplit(Cabin,"/"), `[`, 3)))

df <- select(df, -Cabin)
```

Tras crear las nuevas variables derivadas se elimina *Cabin* porque ya tenemos su información separada. PassengerId no se eliminará porque sirve para identificar los registros. Se muestra un resumen de los campos con la función *summary*.

```{r}
summary(df)
```

Cabe destacar que en *HomePlanet* y en *Destination* hay campos con valores vacíos que no se han considerado como NA's. Por otro lado, Hay algunos campos que presenta NA's que podrán tratarse o desestimarse. También se observan valores extremos en algunos campos.

# 3 Limpieza de los Datos.
En este apartado se tratará de mejorar la calidad de los datos presentes en base a la falta de calidad. Por límite de extensión del proyecto, nos centraremos en el tratamiento de outliers y de valores nulos.

## 3.1 Tratamiento valores nulos.
Se remapean los campos en blanco de los campos *HomePlanet* y *Destination* por el valor *Unknown*. Con esto, no perdemos información y evitamos confundir a las personas que interpreten los resultados.

```{r}
levels(df$HomePlanet) <- c("Unknown", "Earth", "Europa", "Mars")
levels(df$Destination) <- c("Unknown", "55 Cancri e", "PSO J318.5-22",
                            "TRAPPIST-1e")
```

Se muestran la cantidad de valores nulos que tiene cada campo.
```{r}
sapply(df, function(x) sum(length(which(is.na(x)))))
```
Son relativamente pocos registros en comparación con el total que constan en el dataset. Por lo que se decide con contar con estos registros para entrenar al modelo predictivo.

```{r}
nrow(df)
df <- na.omit(df)
nrow(df)
```

## 3.2 Tratamiento valores extremos.

```{r}
attach(df)
boxplot(RoomService)
boxplot(FoodCourt)
boxplot(ShoppingMall)
boxplot(Spa)
boxplot(VRDeck)
detach(df)
```

Aunque encontramos valores muy alejados de los valores centrales. No se consideraran como valores extremos. Se considerarán valores atípicos pero que son representativos de la variedad de nuestra muestra y por tanto formarán parte de los datos para entrenar al modelo. No se eliminará ningún valor extremo.

# 4 Análisis de los datos
## 4.1

## 4.2 Comprobación de la normalidad y homogeneidad de la varianza

Debido a la naturaleza de las variables, se deberá estudiar la normalidad y varianza para las variables numéricas. No tiene sentido estudiar si se distribuye normalmente o con que varianza lo hace una variable categórica. Es decir, se estudiará sobre las variables *Age*,*RoomService*, *FoodCourt*, *ShoppingMall*, *Spa* y *VRDeck*.

A continuación se detalla el **estudio de la normalidad**. Debido a que, la cantidad de registros es superior a 5 000, se  usará el test de normalidad de *Anderson-Darling*, ya que el test de *Shapiro-Wilk* tiene como limitación un valor máx. de 5 000 registros.

```{r, out.width="60%", fig.align='center'}
par(mfrow=c(1,2))

hist(df$RoomService)
qqnorm(df$RoomService, main="Q-Q RoomService")
qqline(df$RoomService,col=2)

ad.test(df$RoomService)
```
Gráficamente se observa que no sigue una distribución normal. Si realizamos el test de normalidad de *Anderson-Daling* nos da un p-valor < 0,05. Por lo que se rechaza la hipótesis nula que indica que los datos siguen una distribución normal.  

```{r, out.width="60%", fig.align='center'}
par(mfrow=c(1,2))

hist(df$FoodCourt)
qqnorm(df$FoodCourt, main="Q-Q FoodCourt")
qqline(df$FoodCourt,col=2)

ad.test(df$FoodCourt)
```

Gráficamente se observa que no sigue una distribución normal. Si realizamos el test de normalidad de *Anderson-Daling* nos da un p-valor < 0,05. Por lo que se rechaza la hipótesis nula que indica que los datos siguen una distribución normal.

```{r, out.width="60%", fig.align='center'}
par(mfrow=c(1,2))

hist(df$ShoppingMall)
qqnorm(df$ShoppingMall, main="Q-Q ShoppingMall")
qqline(df$ShoppingMall,col=2)

ad.test(df$ShoppingMall)
```

Gráficamente se observa que no sigue una distribución normal. Si realizamos el test de normalidad de *Anderson-Daling* nos da un p-valor < 0,05. Por lo que se rechaza la hipótesis nula que indica que los datos siguen una distribución normal.

```{r, out.width="60%", fig.align='center'}
par(mfrow=c(1,2))

hist(df$Spa)
qqnorm(df$Spa, main="Q-Q Spa")
qqline(df$Spa,col=2)

ad.test(df$Spa)
```

Gráficamente se observa que no sigue una distribución normal. Si realizamos el test de normalidad de *Anderson-Daling* nos da un p-valor < 0,05. Por lo que se rechaza la hipótesis nula que indica que los datos siguen una distribución normal.

```{r, out.width="60%", fig.align='center'}
par(mfrow=c(1,2))

hist(df$VRDeck)
qqnorm(df$VRDeck, main="Q-Q VRDeck")
qqline(df$VRDeck,col=2)

ad.test(df$VRDeck)
```
Gráficamente se observa que no sigue una distribución normal. Si realizamos el test de normalidad de *Anderson-Daling* nos da un p-valor < 0,05. Por lo que se rechaza la hipótesis nula que indica que los datos siguen una distribución normal.

```{r, out.width="60%", fig.align='center'}

par(mfrow=c(1,2))

hist(df$Age)
qqnorm(df$Age, main="Q-Q Age")
qqline(df$Age,col=2)

ad.test(df$Age)
```

Gráficamente se observa que no sigue del todo una distribución normal, hay más datos de los esperados en la parte izquierda de la distribución, por lo que aunque se aproxima no aporta información segura. Si realizamos un test formal de normalidad, como el de *Anderson-Daling*, indica un p-valor < 0,05. Por lo que se rechaza la hipótesis nula que indica que los datos siguen una distribución normal. Si en los siguientes análisis se requiere que los datos sigan una distribución normales, se deberá de proceder a corregir esta.

Tras comprobar la normalidad, se procede a realizar el **análisis de homocedasticidad**. Es decir, se comprueba la igualdad de varianza entre los grupos que se van a comparar. Como los datos no siguen una distribución normal no se aplica el test de *Levene*. En su defecto se usará el test de *Fligner-Killeen*. Con ello comprobaremos si la varianza entre los dos grupos (pasajeros transportados y no transportados) es la misma o no.

Aplicamos a todas las variables numéricas:

```{r, out.width="50%",  fig.align='center'}
fligner.test(RoomService ~Transported, data=df)
boxplot(RoomService~Transported, data = df, 
        main="Comprobación de homocedasticidad para RoomService", 
        ylim=c(0,2000))
```
Se rechaza la hipótesis nula de homocedastitcidad. Por lo que la variable *RoomService* presenta varianzas estadísticamente diferentes para los pasajeros transportados y los no transportados. Se puede observar gráficamente como, los gráficos Boxplot apuntan a la misma conclusión. Se ha establecido en el plot un valor máx. de la variable del eje y como 2000 para observar mejor los IQR.

```{r, out.width="50%",  fig.align='center'}
fligner.test(FoodCourt ~Transported, data=df)
boxplot(FoodCourt~Transported, data = df, 
        main="Comprobación de homocedasticidad para FoodCourt", 
        ylim=c(0,500))
```

Se rechaza la hipótesis nula, la variable *FoodCour* presenta heterocestasicidad en los grupos definidos por *Transported*. Se puede observar gráficamente como, los gráficos Boxplot apuntan a la misma conclusión. Se ha establecido en el plot un valor máx. de la variable del eje y como 500 para observar mejor los IQR.

```{r, out.width="50%",  fig.align='center'}
fligner.test(ShoppingMall ~Transported, data=df)
boxplot(ShoppingMall~Transported, data = df, 
        main="Comprobación de homocedasticidad para ShoppingMall",
        ylim=c(0,300))
```

Se rechaza la hipótesis nula de homocedastitcidad. Por lo que la variable *ShoppingMall* presenta varianzas estadísticamente diferentes para los pasajeros transportados y los no transportados. Se puede observar gráficamente como, los gráficos Boxplot apuntan a la misma conclusión. Se ha establecido en el plot un valor máx. de la variable del eje y como 300 para observar mejor los IQR.

```{r, out.width="50%",  fig.align='center'}
fligner.test(Spa ~Transported, data=df)
boxplot(Spa~Transported, data = df, 
        main="Comprobación de homocedasticidad para Spa", 
        ylim=c(0,1500))
```
Se rechaza la hipótesis nula, la variable *Spa* presenta heterocestasicidad en los grupos definidos por *Transported*. Se puede observar gráficamente como, los gráficos Boxplot apuntan a la misma conclusión. Se ha establecido en el plot un valor máx. de la variable del eje y como 1500 para observar mejor los IQR.

```{r, out.width="50%",  fig.align='center'}
fligner.test(VRDeck ~Transported, data=df)
boxplot(VRDeck~Transported, data = df, 
        main="Comprobación de homocedasticidad para VRDeck", ylim=c(0,1200))
```

Se rechaza la hipótesis nula, la variable *VRDeck* presenta heterocestasicidad en los grupos definidos por *Transported*. Se puede observar gráficamente como, los gráficos Boxplot apuntan a la misma conclusión. Se ha establecido en el plot un valor máx. de la variable del eje y como 1200 para observar mejor los IQR.

```{r, out.width="50%",  fig.align='center'}
fligner.test(Age ~ Transported, data=df)
boxplot(Age~Transported, data = df, 
        main="Comprobación de homocedasticidad para Age")
```
Aunque gráficamente parece que la varianza es homogénea para los dos grupos de la variable *Age* definidos por *Transported*, el test de *Fligner-Killeen* apunta a que no son iguales. El p-valor apportado es inferior a 0.05 por lo que se rechaza la hipótesis nula de igualdad de varianzas.

Por lo que se afirma que **ninguno de los campos numéricos sigue una distribución normal, ni presentan homocedasticidad** para los dos grupos definidos por la variable *Transported*. Se observa en cuantro a la distribución normal. Que en todas las variables (salvo en *Age*) el grupo asignado como "TRUE" tiene muchos más valores en 0 (lo que indica que no han gastado nada en esos servicios) que el asignado como "FALSE."

## 4.3

### 4.3.2 Contraste de hipótesis.

Se realizará un contraste de hipótesis en el que se estudiará si el gato total de dos submuestras, siendo una las personas con TRUE en Transported y las segundas las personas con FALSE.

En primer lugar, se crea una variable denominada *amountSpent*, esta será la suma de todas las variables relacionadas con el gasto. Se hace un head para ver los valores de los primeros registros.

```{r}
df <- df %>%
  mutate(amountSpent = RoomService+FoodCourt+ShoppingMall+Spa+VRDeck)
kable(cbind("amountSpent"=head(df)$amountSpent), align = 'c')
```

Con esta, se plantea la pregunta de investigación:

**¿Es diferente la media del total gastado de las personas transportadas **$\mu_1$ **que la media del total gastado de las personas no transportadas ** $\mu_2$ **?**

La formulación del contraste de hipótesis nula y alternativa es la siguiente:

$$
H_0: \mu_1 = \mu_2
$$
$$
H_1: \mu_1 \neq \mu_2
$$

Como las muestras no siguen una distribución normal se usará un test para realizar el contraste NO paramétrico de dos muestras independientes. Este test será el **test de suma de rangos de Wilcoxon**.

```{r}
amountSpenteTransported <- filter(df, Transported==TRUE)$amountSpent

amountSpenteNOTransported <- filter(df, Transported==FALSE)$amountSpent

wilcox.test(amountSpenteNOTransported, amountSpenteTransported)
```
Con un p-valor inferior al valor de significancia de 0.05, no hay evidencia suficiente para aceptar la hipótesis nula. Por lo que se puede concluir que la media de la cantidad total de dinero gastada por las personas Transportadas y las No transportadas no es estadísticamente igual.

### 4.3.3 Modelo de regresión logarítmica

Se usará un modelo de regresivo logística que permitirá identificar a los pasajeros entre transportados o no transportados. Para ello hará uso de las variables explicativas que determinarán en la medida de lo posible si estos pasajeros toman un valor u otro.

Se parten los datos en *df* para entrenar al modelo con un 70% de los casos y en *df_validation* para medir la bondad del modelo con el 30% restante.

```{r, warning=FALSE}
df_raw <- df

Index <- createDataPartition(df_raw$Transported, p=0.7, list=FALSE,times=1)

df <- df_raw[Index,]
df_validation <- df_raw[-Index,]
```


Aunque no se incluye en la práctica por motivos de extensión. Se han realizado análisis previos y se ha determinado que hay variables que empeoran el modelo, por lo que estas se eliminan en el entrenamiento y en la validación.
```{r}
df1 <- select(df, -c(PassengerId, PassengerGroup, HomePlanet, Destination,VIP, PassengerNumInGroup, CabinPlatform, Age, amountSpent))
```

Se entrena el modelo con el dataset previamente creado. Se presupone que lasvariables no son bariables de confusión y no presentan interacción entre ellas.

```{r}
model_log <- glm(Transported ~ ., data = df1, family = binomial(link='logit'))
summary(model_log)
```

A continuación se evalúa el mismo. Para ello se predicen los valores del conjunto *df_validation* y se comparan con los valres reales del mismo.

```{r}
fitted.results <- predict(model_log, 
                          newdata = select(df_validation, c(CryoSleep,
                                                            RoomService,
                                                            FoodCourt,
                                                            ShoppingMall,
                                                            Spa,VRDeck,
                                                            CabinNumber,
                                                            CabinSide))
                          ,type = "response")
```


```{r}
fitted.results_FACTOR <- ifelse(fitted.results > 0.5,TRUE,FALSE)

resultado_comprobacion <- cbind("ID"=df_validation$PassengerId, 
                                "Transported"=df_validation$Transported,
                                "Prediction"=fitted.results_FACTOR)

df_validation_info <- as.data.frame(resultado_comprobacion)
kable(head(df_validation_info),align='c', row.names=FALSE)
```

Se convierten las variables *Transported* (valor real) y *Prediction* (valor predicho) y se mide la bondad del modelo con la matriz de confusión mediante la función *confusionMatrix).

```{r}
df_validation_info$Transported <- as.factor(df_validation_info$Transported)
df_validation_info$Prediction <- as.factor(df_validation_info$Prediction)

confusionMatrix(df_validation_info$Transported, df_validation_info$Prediction)
```
La clase positiva se categoriza como FALSE (no desaparecido).

Se observa una buena predicción de las clases. Con una exactitud del 80,38%. La tasa de positivos que se han asignado como positivos es del 81,27%. mientras que los negativos identificado como auténticos negativos es del 79,55%. De los verdaderos.

La precisión, es decir, los datos clasificados como positivos y que realmente lo son es del  78,73%.

```{r, out.width="70%",  fig.align='center'}
pr <- prediction(fitted.results, df_validation$Transported)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
```

```{r}
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```

Vemos como la curva ROC nos da un valor próxima a la esquina superior derecha y un área del 0.85, muy próximo a 1.

Se observa que el modelo es bueno prediciendo si los pasajeros han desaparecido o no.